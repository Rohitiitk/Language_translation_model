{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeep2c1/Machine-Translation-model/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aByTLISdCSpp"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        " \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvs3YYFrYXmN",
        "outputId": "936355b6-4805-4255-f2db-63446474b132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Aug 27 11:48:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 536.25                 Driver Version: 536.25       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1650      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "| N/A   44C    P8               2W /  20W |    824MiB /  4096MiB |      2%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1888    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      2160    C+G   ...t Office\\root\\Office16\\POWERPNT.EXE    N/A      |\n",
            "|    0   N/A  N/A      4448    C+G   ...3.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
            "|    0   N/A  N/A      4552    C+G   C:\\Windows\\PrintDialog\\PrintDialog.exe    N/A      |\n",
            "|    0   N/A  N/A      5980    C+G   ...n\\127.0.2651.105\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A      9836    C+G   ...AB\\R2023b\\bin\\win64\\MATLABWebUI.exe    N/A      |\n",
            "|    0   N/A  N/A     11012    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
            "|    0   N/A  N/A     11512    C+G   ...t Office\\root\\Office16\\POWERPNT.EXE    N/A      |\n",
            "|    0   N/A  N/A     11732    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     12328    C+G   ...\\MATLAB\\R2023b\\bin\\win64\\MATLAB.exe    N/A      |\n",
            "|    0   N/A  N/A     13932    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     13956    C+G   ...n\\127.0.2651.105\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     15548    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     19028    C+G   ...J\\AppData\\Roaming\\Zoom\\bin\\Zoom.exe    N/A      |\n",
            "|    0   N/A  N/A     19504    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
            "|    0   N/A  N/A     20852    C+G   ...\\Docker\\frontend\\Docker Desktop.exe    N/A      |\n",
            "|    0   N/A  N/A     22820    C+G   ...al\\Discord\\app-1.0.9159\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A     24640    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A     32236    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     38400    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     39468    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     39584    C+G   ...Brave-Browser\\Application\\brave.exe    N/A      |\n",
            "|    0   N/A  N/A     40588    C+G   ...3.0_x64__g9c9v27vpyspw\\Telegram.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kcz51fdAYp_8",
        "outputId": "08d6dc6e-ce6b-4b7f-8283-70d0864babe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4dOWFN2YO83"
      },
      "source": [
        "# Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8B5h0UHMmEgQ"
      },
      "outputs": [],
      "source": [
        "lines = pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\", encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REzTYEAEmYlu",
        "outputId": "656c2d6d-8995-4fdc-f500-5960b824bd05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "source\n",
              "tides        50000\n",
              "ted          39881\n",
              "indic2012    37726\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines['source'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NU6z_ZbLs8N7",
        "outputId": "dd856585-db0d-4035-ece1-25fe770eafce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ted</td>\n",
              "      <td>And who are we to say, even, that they are wrong</td>\n",
              "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ted</td>\n",
              "      <td>So there is some sort of justice</td>\n",
              "      <td>तो वहाँ न्याय है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ted</td>\n",
              "      <td>This changed slowly</td>\n",
              "      <td>धीरे धीरे ये सब बदला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ted</td>\n",
              "      <td>were being produced.</td>\n",
              "      <td>उत्पन्न नहीं कि जाती थी.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>ted</td>\n",
              "      <td>And you can see, this LED is going to glow.</td>\n",
              "      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>ted</td>\n",
              "      <td>to turn on the lights or to bring him a glass ...</td>\n",
              "      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ted</td>\n",
              "      <td>Can you imagine saying that?</td>\n",
              "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source                                   english_sentence  \\\n",
              "0     ted  politicians do not have permission to do what ...   \n",
              "1     ted         I'd like to tell you about one such child,   \n",
              "3     ted  what we really mean is that they're bad at not...   \n",
              "7     ted   And who are we to say, even, that they are wrong   \n",
              "13    ted                   So there is some sort of justice   \n",
              "23    ted                                This changed slowly   \n",
              "26    ted                               were being produced.   \n",
              "30    ted        And you can see, this LED is going to glow.   \n",
              "32    ted  to turn on the lights or to bring him a glass ...   \n",
              "35    ted                       Can you imagine saying that?   \n",
              "\n",
              "                                       hindi_sentence  \n",
              "0   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1   मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "3      हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "7    और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
              "13                                   तो वहाँ न्याय है  \n",
              "23                               धीरे धीरे ये सब बदला  \n",
              "26                           उत्पन्न नहीं कि जाती थी.  \n",
              "30       और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।  \n",
              "32    लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,  \n",
              "35                       क्या आप ये कल्पना कर सकते है  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines = lines[lines['source'] == 'ted']\n",
        "lines.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWUF8i3eNBNG",
        "outputId": "f3baa0b6-982b-42f1-f235-5b3704c179b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(39881, 2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines.drop(columns = ['source'], inplace = True)\n",
        "lines.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8Y7POK6xYn3r"
      },
      "outputs": [],
      "source": [
        "lines.reset_index(inplace = True)\n",
        "lines.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmpewEf60IGd",
        "outputId": "2256d44f-a7fa-46e2-a4e5-eb0f422d47ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "english_sentence    0\n",
              "hindi_sentence      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.isnull(lines).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbHkhHLk8_S0",
        "outputId": "f79a482f-a6fc-4ee0-f998-52298d1b2f55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(38803, 2)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines.drop_duplicates(inplace=True)\n",
        "lines.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jLLZJ7tdX_38",
        "outputId": "951f88a8-5fc6-4cd7-a85f-7a86ee87a007"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And who are we to say, even, that they are wrong</td>\n",
              "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So there is some sort of justice</td>\n",
              "      <td>तो वहाँ न्याय है</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    english_sentence  \\\n",
              "0  politicians do not have permission to do what ...   \n",
              "1         I'd like to tell you about one such child,   \n",
              "2  what we really mean is that they're bad at not...   \n",
              "3   And who are we to say, even, that they are wrong   \n",
              "4                   So there is some sort of justice   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "3   और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
              "4                                   तो वहाँ न्याय है  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vtTASV7GHewD"
      },
      "outputs": [],
      "source": [
        "# Make all english letters lowercase\n",
        "lines['english_sentence'] = lines['english_sentence'].apply(lambda x: x.lower())\n",
        "\n",
        "# Remove the quotes\n",
        "lines['english_sentence'] = lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "\n",
        "# Remove special characters\n",
        "sp_char = set(string.punctuation)\n",
        "lines['english_sentence'] = lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sp_char))\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sp_char))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KfuxP2pXYO9E"
      },
      "outputs": [],
      "source": [
        "# Remove extra spaces\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RJZsWTHZnlY1"
      },
      "outputs": [],
      "source": [
        "# Add START and END tokens to the beginning and end of the target sequence\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: 'START_ ' + x + ' _END')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O1jcj84GLMVM",
        "outputId": "f6d2fbf8-24a8-42b1-93fc-ef443246bde8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id like to tell you about one such child</td>\n",
              "      <td>START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what we really mean is that theyre bad at not ...</td>\n",
              "      <td>START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>and who are we to say even that they are wrong</td>\n",
              "      <td>START_ और हम होते कौन हैं यह कहने भी वाले कि व...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>so there is some sort of justice</td>\n",
              "      <td>START_ तो वहाँ न्याय है _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    english_sentence  \\\n",
              "0  politicians do not have permission to do what ...   \n",
              "1           id like to tell you about one such child   \n",
              "2  what we really mean is that theyre bad at not ...   \n",
              "3     and who are we to say even that they are wrong   \n",
              "4                   so there is some sort of justice   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...  \n",
              "1  START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...  \n",
              "2  START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...  \n",
              "3  START_ और हम होते कौन हैं यह कहने भी वाले कि व...  \n",
              "4                       START_ तो वहाँ न्याय है _END  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6tOma5CQYl8X",
        "outputId": "db46aef2-51d0-4293-98ab-c36115d64a23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we developed these novel actuators for joints</td>\n",
              "      <td>START_ हमने जोड़ो के लिए उत्तम actuators बनाये...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and we would see ourselves on tv pasting</td>\n",
              "      <td>START_ और हम अपने आपको टीवी पर देखते तसवीरें च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>and heres an example of a file</td>\n",
              "      <td>START_ और यहाँ एक फ़ाइल का एक उदाहरण है _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>and calculate the control commands</td>\n",
              "      <td>START_ और नियंत्रण आदेशो की गणना करता है _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this which is helicodiceros</td>\n",
              "      <td>START_ यह हेलिकोदिक्रोस है _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                english_sentence  \\\n",
              "0  we developed these novel actuators for joints   \n",
              "1       and we would see ourselves on tv pasting   \n",
              "2                 and heres an example of a file   \n",
              "3             and calculate the control commands   \n",
              "4                    this which is helicodiceros   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  START_ हमने जोड़ो के लिए उत्तम actuators बनाये...  \n",
              "1  START_ और हम अपने आपको टीवी पर देखते तसवीरें च...  \n",
              "2       START_ और यहाँ एक फ़ाइल का एक उदाहरण है _END  \n",
              "3      START_ और नियंत्रण आदेशो की गणना करता है _END  \n",
              "4                    START_ यह हेलिकोदिक्रोस है _END  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines = lines.sample(frac = 1).reset_index(drop = True)\n",
        "lines.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQY65UsEYO-h"
      },
      "source": [
        "# Tokenizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z6Gh2jx0YO-j"
      },
      "outputs": [],
      "source": [
        "en = set()\n",
        "for sentence in lines['english_sentence']:\n",
        "    for word in sentence.split():\n",
        "        if word not in en:\n",
        "            en.add(word)\n",
        "\n",
        "hi = set()\n",
        "for sentence in lines['hindi_sentence']:\n",
        "    for word in sentence.split():\n",
        "        if word not in hi:\n",
        "            hi.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV8sLvrnYO-k",
        "outputId": "87a1833c-aeab-44b4-811a-50cc1143b035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique words in English are :  17759\n",
            "Unique words in Hindi are :  22782\n"
          ]
        }
      ],
      "source": [
        "print('Unique words in English are : ', len(en))\n",
        "print('Unique words in Hindi are : ', len(hi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NBF2-ex1YO-m",
        "outputId": "12e90d91-f677-43be-fa97-f10d93a859ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>length_en</th>\n",
              "      <th>length_hi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we developed these novel actuators for joints</td>\n",
              "      <td>START_ हमने जोड़ो के लिए उत्तम actuators बनाये...</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and we would see ourselves on tv pasting</td>\n",
              "      <td>START_ और हम अपने आपको टीवी पर देखते तसवीरें च...</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>and heres an example of a file</td>\n",
              "      <td>START_ और यहाँ एक फ़ाइल का एक उदाहरण है _END</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>and calculate the control commands</td>\n",
              "      <td>START_ और नियंत्रण आदेशो की गणना करता है _END</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this which is helicodiceros</td>\n",
              "      <td>START_ यह हेलिकोदिक्रोस है _END</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                english_sentence  \\\n",
              "0  we developed these novel actuators for joints   \n",
              "1       and we would see ourselves on tv pasting   \n",
              "2                 and heres an example of a file   \n",
              "3             and calculate the control commands   \n",
              "4                    this which is helicodiceros   \n",
              "\n",
              "                                      hindi_sentence  length_en  length_hi  \n",
              "0  START_ हमने जोड़ो के लिए उत्तम actuators बनाये...          7         10  \n",
              "1  START_ और हम अपने आपको टीवी पर देखते तसवीरें च...          8         12  \n",
              "2       START_ और यहाँ एक फ़ाइल का एक उदाहरण है _END          7         10  \n",
              "3      START_ और नियंत्रण आदेशो की गणना करता है _END          5          9  \n",
              "4                    START_ यह हेलिकोदिक्रोस है _END          4          5  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines['length_en'] = lines['english_sentence'].apply(lambda x: len(x.split()))\n",
        "lines['length_hi'] = lines['hindi_sentence'].apply(lambda x: len(x.split()))\n",
        "\n",
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBdYEMDCYO-o",
        "outputId": "70c3250d-83f5-47d3-980a-9a39ee01443e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 4)\n",
            "(334, 4)\n"
          ]
        }
      ],
      "source": [
        "print(lines[lines['length_en'] > 20].shape)\n",
        "print(lines[lines['length_hi'] > 20].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EleKwN6ZYO-p",
        "outputId": "ecc9b403-03b1-472a-df96-08f33c3609dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(38469, 4)\n"
          ]
        }
      ],
      "source": [
        "lines = lines[lines['length_en'] <= 20]\n",
        "lines = lines[lines['length_hi'] <= 20]\n",
        "print(lines.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTgOsAssYO-q",
        "outputId": "51c3acdb-1f9d-4f15-8b05-a91b82c353a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum sequence length of inputs = 20\n",
            "Maximum sequence length of outputs = 20\n"
          ]
        }
      ],
      "source": [
        "print(\"Maximum sequence length of inputs =\", max(lines['length_en']))\n",
        "print(\"Maximum sequence length of outputs =\", max(lines['length_hi']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6U7JUwqYO-r",
        "outputId": "1c0a906a-8f52-402a-ca5f-b3221cae7f8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17759, 22782)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_encoder_seq_length = max(lines['length_en'])\n",
        "max_decoder_seq_length = max(lines['length_hi'])\n",
        "\n",
        "input_words = sorted(list(en))\n",
        "target_words = sorted(list(hi))\n",
        "num_encoder_tokens = len(en)\n",
        "num_decoder_tokens = len(hi)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5iP6_8xWYO-s"
      },
      "outputs": [],
      "source": [
        "num_encoder_tokens += 1\n",
        "num_decoder_tokens += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HwHCkRaCYO-s"
      },
      "outputs": [],
      "source": [
        "input_token_id = dict([(word, i + 1) for i, word in enumerate(input_words)])\n",
        "target_token_id = dict([(word, i + 1) for i, word in enumerate(target_words)])\n",
        "\n",
        "rev_input_char_id = dict((i, word) for word, i in input_token_id.items())\n",
        "rev_target_char_id = dict((i, word) for word, i in target_token_id.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9EP4jnd3YO-v",
        "outputId": "453bf47d-3923-4963-facb-a72c9d115559"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>length_en</th>\n",
              "      <th>length_hi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27537</th>\n",
              "      <td>and this is where we are today</td>\n",
              "      <td>START_ और हम यहाँ है अभी। _END</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11657</th>\n",
              "      <td>where passengers on the ferry</td>\n",
              "      <td>START_ जहाँ फेरी के यात्रियों ने _END</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5812</th>\n",
              "      <td>where no sentient creature is harmed</td>\n",
              "      <td>START_ जहां कोई संवेदनशील प्राणी को नुकसान नही...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4695</th>\n",
              "      <td>doesnt feel like anything</td>\n",
              "      <td>START_ कुछ भी महसूस नहीं करता है _END</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9597</th>\n",
              "      <td>it would be necessary to look at the brain dir...</td>\n",
              "      <td>START_ मस्तिष्क को सीधे ही देखना आवश्यक होना च...</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        english_sentence  \\\n",
              "27537                     and this is where we are today   \n",
              "11657                      where passengers on the ferry   \n",
              "5812                where no sentient creature is harmed   \n",
              "4695                           doesnt feel like anything   \n",
              "9597   it would be necessary to look at the brain dir...   \n",
              "\n",
              "                                          hindi_sentence  length_en  length_hi  \n",
              "27537                     START_ और हम यहाँ है अभी। _END          7          7  \n",
              "11657              START_ जहाँ फेरी के यात्रियों ने _END          5          7  \n",
              "5812   START_ जहां कोई संवेदनशील प्राणी को नुकसान नही...          6         11  \n",
              "4695               START_ कुछ भी महसूस नहीं करता है _END          4          8  \n",
              "9597   START_ मस्तिष्क को सीधे ही देखना आवश्यक होना च...         10         10  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7mYyZwxYO-w"
      },
      "source": [
        "# Splitting the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U96xDKRCYO-x",
        "outputId": "7ea5e730-66e3-4f6f-bdad-b1d75b40c1f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((30775,), (7694,))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Splitting data set into 80/20 for train/test data\n",
        "split = int(0.8 * len(lines))\n",
        "\n",
        "train_set = lines[: split]\n",
        "test_set = lines[split :]\n",
        "\n",
        "x_train, y_train = train_set['english_sentence'], train_set['hindi_sentence']\n",
        "x_test, y_test = test_set['english_sentence'], test_set['hindi_sentence']\n",
        "\n",
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Fg14VuvRYO-x"
      },
      "outputs": [],
      "source": [
        "def generate_batch(x = x_train, y = y_train, batch_size = 128):\n",
        "    while True:\n",
        "        for j in range(0, len(x), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_encoder_seq_length), dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_decoder_seq_length), dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(x[j:j + batch_size], y[j:j + batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_id[word]   # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):    \n",
        "                    if t < len(target_text.split()) - 1:\n",
        "                        decoder_input_data[i, t] = target_token_id[word]   # decoder input seq\n",
        "                    if t > 0:\n",
        "                        # does not include the START_ token\n",
        "                        decoder_target_data[i, t - 1, target_token_id[word]] = 1. \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja4i8fHxYO-y"
      },
      "source": [
        "# Making the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jec-XDmOYO-y"
      },
      "outputs": [],
      "source": [
        "latent_dim = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qBIe7hVrYO-z"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(None,))  # Create the input tensor\n",
        "encoder_embedding =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "# We discard encoder_outputs and only keep the states\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bUspq8-YYO-z"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using encoder_states as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        " \n",
        "# We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn encoder_input_data & decoder_input_data into decoder_target_data\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "itRNktldYO-0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm7oYPXmYO-0",
        "outputId": "07262a19-36f4-4e9a-807a-d2346b71c9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 256)            4546816   ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 256)            5832704   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 256),                525312    ['embedding[0][0]']           \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 256),          525312    ['embedding_1[0][0]',         \n",
            "                              (None, 256),                           'lstm[0][1]',                \n",
            "                              (None, 256)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 22784)          5855488   ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17285632 (65.94 MB)\n",
            "Trainable params: 17285632 (65.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_c9OmNRDYO-0"
      },
      "outputs": [],
      "source": [
        "train_samples = len(x_train)\n",
        "val_samples = len(x_test)\n",
        "batch_size = 128\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIR25NADYO-1",
        "outputId": "88a20ee4-ccf4-462a-e6bc-335b938c4d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "240/240 [==============================] - 419s 2s/step - loss: 6.6972 - val_loss: 6.2043\n",
            "Epoch 2/100\n",
            "240/240 [==============================] - 384s 2s/step - loss: 5.9052 - val_loss: 5.8430\n",
            "Epoch 3/100\n",
            "240/240 [==============================] - 378s 2s/step - loss: 5.5250 - val_loss: 5.6480\n",
            "Epoch 4/100\n",
            "240/240 [==============================] - 373s 2s/step - loss: 5.2632 - val_loss: 5.5371\n",
            "Epoch 5/100\n",
            "240/240 [==============================] - 374s 2s/step - loss: 5.0377 - val_loss: 5.4517\n",
            "Epoch 6/100\n",
            "240/240 [==============================] - 377s 2s/step - loss: 4.8278 - val_loss: 5.3868\n",
            "Epoch 7/100\n",
            "240/240 [==============================] - 380s 2s/step - loss: 4.6203 - val_loss: 5.3216\n",
            "Epoch 8/100\n",
            "240/240 [==============================] - 376s 2s/step - loss: 4.4187 - val_loss: 5.2864\n",
            "Epoch 9/100\n",
            "240/240 [==============================] - 377s 2s/step - loss: 4.2216 - val_loss: 5.2666\n",
            "Epoch 10/100\n",
            "240/240 [==============================] - 380s 2s/step - loss: 4.0316 - val_loss: 5.2489\n",
            "Epoch 11/100\n",
            "240/240 [==============================] - 378s 2s/step - loss: 3.8506 - val_loss: 5.2573\n",
            "Epoch 12/100\n",
            "240/240 [==============================] - 391s 2s/step - loss: 3.6783 - val_loss: 5.2717\n",
            "Epoch 13/100\n",
            "240/240 [==============================] - 387s 2s/step - loss: 3.5101 - val_loss: 5.2696\n",
            "Epoch 14/100\n",
            "240/240 [==============================] - 382s 2s/step - loss: 3.3475 - val_loss: 5.3030\n",
            "Epoch 15/100\n",
            "240/240 [==============================] - 378s 2s/step - loss: 3.1884 - val_loss: 5.3467\n",
            "Epoch 16/100\n",
            "240/240 [==============================] - 382s 2s/step - loss: 3.0320 - val_loss: 5.3840\n",
            "Epoch 17/100\n",
            "240/240 [==============================] - 379s 2s/step - loss: 2.8830 - val_loss: 5.4112\n",
            "Epoch 18/100\n",
            "240/240 [==============================] - 381s 2s/step - loss: 2.7406 - val_loss: 5.4355\n",
            "Epoch 19/100\n",
            "240/240 [==============================] - 381s 2s/step - loss: 2.6035 - val_loss: 5.4703\n",
            "Epoch 20/100\n",
            "240/240 [==============================] - 380s 2s/step - loss: 2.4753 - val_loss: 5.5136\n",
            "Epoch 21/100\n",
            "240/240 [==============================] - 382s 2s/step - loss: 2.3566 - val_loss: 5.5874\n",
            "Epoch 22/100\n",
            "240/240 [==============================] - 389s 2s/step - loss: 2.2465 - val_loss: 5.6325\n",
            "Epoch 23/100\n",
            "240/240 [==============================] - 389s 2s/step - loss: 2.1378 - val_loss: 5.6726\n",
            "Epoch 24/100\n",
            "240/240 [==============================] - 386s 2s/step - loss: 2.0328 - val_loss: 5.7217\n",
            "Epoch 25/100\n",
            "240/240 [==============================] - 382s 2s/step - loss: 1.9322 - val_loss: 5.7973\n",
            "Epoch 26/100\n",
            "240/240 [==============================] - 385s 2s/step - loss: 1.8374 - val_loss: 5.8438\n",
            "Epoch 27/100\n",
            "240/240 [==============================] - 382s 2s/step - loss: 1.7476 - val_loss: 5.8871\n",
            "Epoch 28/100\n",
            "240/240 [==============================] - 386s 2s/step - loss: 1.6642 - val_loss: 5.9768\n",
            "Epoch 29/100\n",
            "240/240 [==============================] - 388s 2s/step - loss: 1.5823 - val_loss: 6.0391\n",
            "Epoch 30/100\n",
            "240/240 [==============================] - 402s 2s/step - loss: 1.5042 - val_loss: 6.0730\n",
            "Epoch 31/100\n",
            "240/240 [==============================] - 391s 2s/step - loss: 1.4273 - val_loss: 6.1561\n",
            "Epoch 32/100\n",
            "240/240 [==============================] - 398s 2s/step - loss: 1.3581 - val_loss: 6.2466\n",
            "Epoch 33/100\n",
            "240/240 [==============================] - 396s 2s/step - loss: 1.2866 - val_loss: 6.2805\n",
            "Epoch 34/100\n",
            "240/240 [==============================] - 373s 2s/step - loss: 1.2204 - val_loss: 6.3497\n",
            "Epoch 35/100\n",
            "240/240 [==============================] - 363s 2s/step - loss: 1.1555 - val_loss: 6.4285\n",
            "Epoch 36/100\n",
            "240/240 [==============================] - 335s 1s/step - loss: 1.0953 - val_loss: 6.4912\n",
            "Epoch 37/100\n",
            "240/240 [==============================] - 367s 2s/step - loss: 1.0376 - val_loss: 6.5733\n",
            "Epoch 38/100\n",
            "240/240 [==============================] - 329s 1s/step - loss: 0.9832 - val_loss: 6.6478\n",
            "Epoch 39/100\n",
            "240/240 [==============================] - 351s 1s/step - loss: 0.9283 - val_loss: 6.7244\n",
            "Epoch 40/100\n",
            "240/240 [==============================] - 374s 2s/step - loss: 0.8757 - val_loss: 6.8185\n",
            "Epoch 41/100\n",
            "240/240 [==============================] - 369s 2s/step - loss: 0.8244 - val_loss: 6.9119\n",
            "Epoch 42/100\n",
            "240/240 [==============================] - 376s 2s/step - loss: 0.7800 - val_loss: 6.9534\n",
            "Epoch 43/100\n",
            "240/240 [==============================] - 349s 1s/step - loss: 0.7355 - val_loss: 7.0648\n",
            "Epoch 44/100\n",
            "240/240 [==============================] - 378s 2s/step - loss: 0.6904 - val_loss: 7.1116\n",
            "Epoch 45/100\n",
            "240/240 [==============================] - 343s 1s/step - loss: 0.6494 - val_loss: 7.1583\n",
            "Epoch 46/100\n",
            "240/240 [==============================] - 360s 2s/step - loss: 0.6080 - val_loss: 7.2433\n",
            "Epoch 47/100\n",
            "240/240 [==============================] - 399s 2s/step - loss: 0.5698 - val_loss: 7.3069\n",
            "Epoch 48/100\n",
            "240/240 [==============================] - 390s 2s/step - loss: 0.5315 - val_loss: 7.3560\n",
            "Epoch 49/100\n",
            "240/240 [==============================] - 410s 2s/step - loss: 0.4966 - val_loss: 7.4608\n",
            "Epoch 50/100\n",
            "240/240 [==============================] - 419s 2s/step - loss: 0.4656 - val_loss: 7.5237\n",
            "Epoch 51/100\n",
            "240/240 [==============================] - 411s 2s/step - loss: 0.4376 - val_loss: 7.6007\n",
            "Epoch 52/100\n",
            "240/240 [==============================] - 380s 2s/step - loss: 0.4097 - val_loss: 7.6803\n",
            "Epoch 53/100\n",
            "240/240 [==============================] - 378s 2s/step - loss: 0.3830 - val_loss: 7.7636\n",
            "Epoch 54/100\n",
            "240/240 [==============================] - 395s 2s/step - loss: 0.3592 - val_loss: 7.8985\n",
            "Epoch 55/100\n",
            "240/240 [==============================] - 375s 2s/step - loss: 0.3352 - val_loss: 7.9613\n",
            "Epoch 56/100\n",
            "240/240 [==============================] - 399s 2s/step - loss: 0.3134 - val_loss: 8.0405\n",
            "Epoch 57/100\n",
            "240/240 [==============================] - 406s 2s/step - loss: 0.2922 - val_loss: 8.1476\n",
            "Epoch 58/100\n",
            "240/240 [==============================] - 379s 2s/step - loss: 0.2739 - val_loss: 8.1714\n",
            "Epoch 59/100\n",
            "240/240 [==============================] - 406s 2s/step - loss: 0.2558 - val_loss: 8.2401\n",
            "Epoch 60/100\n",
            "240/240 [==============================] - 404s 2s/step - loss: 0.2397 - val_loss: 8.3153\n",
            "Epoch 61/100\n",
            "240/240 [==============================] - 376s 2s/step - loss: 0.2247 - val_loss: 8.3898\n",
            "Epoch 62/100\n",
            "240/240 [==============================] - 382s 2s/step - loss: 0.2107 - val_loss: 8.4572\n",
            "Epoch 63/100\n",
            "240/240 [==============================] - 375s 2s/step - loss: 0.1957 - val_loss: 8.5857\n",
            "Epoch 64/100\n",
            "240/240 [==============================] - 374s 2s/step - loss: 0.1802 - val_loss: 8.6064\n",
            "Epoch 65/100\n",
            "240/240 [==============================] - 375s 2s/step - loss: 0.1668 - val_loss: 8.6510\n",
            "Epoch 66/100\n",
            "240/240 [==============================] - 2925s 12s/step - loss: 0.1550 - val_loss: 8.7187\n",
            "Epoch 67/100\n",
            "240/240 [==============================] - 377s 2s/step - loss: 0.1429 - val_loss: 8.8244\n",
            "Epoch 68/100\n",
            "240/240 [==============================] - 385s 2s/step - loss: 0.1312 - val_loss: 8.8860\n",
            "Epoch 69/100\n",
            "240/240 [==============================] - 379s 2s/step - loss: 0.1187 - val_loss: 8.9734\n",
            "Epoch 70/100\n",
            "240/240 [==============================] - 389s 2s/step - loss: 0.1095 - val_loss: 9.0551\n",
            "Epoch 71/100\n",
            "240/240 [==============================] - 404s 2s/step - loss: 0.1013 - val_loss: 9.1340\n",
            "Epoch 72/100\n",
            "240/240 [==============================] - 400s 2s/step - loss: 0.0949 - val_loss: 9.1992\n",
            "Epoch 73/100\n",
            "240/240 [==============================] - 384s 2s/step - loss: 0.0896 - val_loss: 9.2519\n",
            "Epoch 74/100\n",
            "240/240 [==============================] - 349s 1s/step - loss: 0.0847 - val_loss: 9.2972\n",
            "Epoch 75/100\n",
            "240/240 [==============================] - 3363s 14s/step - loss: 0.0805 - val_loss: 9.3592\n",
            "Epoch 76/100\n",
            "240/240 [==============================] - 379s 2s/step - loss: 0.0754 - val_loss: 9.4560\n",
            "Epoch 77/100\n",
            "240/240 [==============================] - 375s 2s/step - loss: 0.0705 - val_loss: 9.5653\n",
            "Epoch 78/100\n",
            "240/240 [==============================] - 394s 2s/step - loss: 0.0652 - val_loss: 9.6339\n",
            "Epoch 79/100\n",
            "240/240 [==============================] - 401s 2s/step - loss: 0.0596 - val_loss: 9.6629\n",
            "Epoch 80/100\n",
            "240/240 [==============================] - 387s 2s/step - loss: 0.0558 - val_loss: 9.7166\n",
            "Epoch 81/100\n",
            "240/240 [==============================] - 400s 2s/step - loss: 0.0539 - val_loss: 9.7617\n",
            "Epoch 82/100\n",
            "240/240 [==============================] - 392s 2s/step - loss: 0.0510 - val_loss: 9.8063\n",
            "Epoch 83/100\n",
            "240/240 [==============================] - 389s 2s/step - loss: 0.0488 - val_loss: 9.8951\n",
            "Epoch 84/100\n",
            "240/240 [==============================] - 391s 2s/step - loss: 0.0474 - val_loss: 9.9333\n",
            "Epoch 85/100\n",
            "240/240 [==============================] - 397s 2s/step - loss: 0.0464 - val_loss: 10.0109\n",
            "Epoch 86/100\n",
            "240/240 [==============================] - 391s 2s/step - loss: 0.0448 - val_loss: 10.1051\n",
            "Epoch 87/100\n",
            "240/240 [==============================] - 389s 2s/step - loss: 0.0421 - val_loss: 10.1498\n",
            "Epoch 88/100\n",
            "240/240 [==============================] - 416s 2s/step - loss: 0.0373 - val_loss: 10.1565\n",
            "Epoch 89/100\n",
            "240/240 [==============================] - 402s 2s/step - loss: 0.0343 - val_loss: 10.2528\n",
            "Epoch 90/100\n",
            "240/240 [==============================] - 425s 2s/step - loss: 0.0327 - val_loss: 10.2862\n",
            "Epoch 91/100\n",
            "240/240 [==============================] - 400s 2s/step - loss: 0.0309 - val_loss: 10.3173\n",
            "Epoch 92/100\n",
            "240/240 [==============================] - 392s 2s/step - loss: 0.0297 - val_loss: 10.3755\n",
            "Epoch 93/100\n",
            "240/240 [==============================] - 402s 2s/step - loss: 0.0279 - val_loss: 10.4151\n",
            "Epoch 94/100\n",
            "240/240 [==============================] - 433s 2s/step - loss: 0.0258 - val_loss: 10.4626\n",
            "Epoch 95/100\n",
            "240/240 [==============================] - 515s 2s/step - loss: 0.0244 - val_loss: 10.5296\n",
            "Epoch 96/100\n",
            "240/240 [==============================] - 542s 2s/step - loss: 0.0253 - val_loss: 10.5887\n",
            "Epoch 97/100\n",
            "240/240 [==============================] - 524s 2s/step - loss: 0.0265 - val_loss: 10.6225\n",
            "Epoch 98/100\n",
            "240/240 [==============================] - 413s 2s/step - loss: 0.0304 - val_loss: 10.6713\n",
            "Epoch 99/100\n",
            "240/240 [==============================] - 409s 2s/step - loss: 0.0380 - val_loss: 10.6933\n",
            "Epoch 100/100\n",
            "240/240 [==============================] - 908s 4s/step - loss: 0.0449 - val_loss: 10.7279\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2067bec4bb0>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    generate_batch(x_train, y_train, batch_size = batch_size),\n",
        "    steps_per_epoch = train_samples//batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = generate_batch(x_test, y_test, batch_size = batch_size),\n",
        "    validation_steps = val_samples//batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "W6k6u7WcYO-2"
      },
      "outputs": [],
      "source": [
        "model.save_weights('nmt_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kxflBi-GYO-2"
      },
      "outputs": [],
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape = (latent_dim,))\n",
        "decoder_state_input_c = Input(shape = (latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate probability over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BRcgVljDYO-2"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_id['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    decoded_sentence = ''\n",
        "    while True:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = rev_target_char_id[sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n",
        "            break\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "pUotQRW-YO-3"
      },
      "outputs": [],
      "source": [
        "train_gen = generate_batch(x_train, y_train, batch_size = 1)\n",
        "k=-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzjd-DM9YO-3",
        "outputId": "d257f735-8a8b-4d5c-819c-4a1362db3da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Input English sentence: and this is where we are today\n",
            "Actual Hindi Translation:  और हम यहाँ है अभी। \n",
            "Predicted Hindi Translation:  और हम यहाँ है अभी। \n"
          ]
        }
      ],
      "source": [
        "k += 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k + 1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3VpE5tiYO-4",
        "outputId": "79cccfd0-3f2a-4410-bbc8-293b80e11766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Input English sentence: where passengers on the ferry\n",
            "Actual Hindi Translation:  जहाँ फेरी के यात्रियों ने \n",
            "Predicted Hindi Translation:  जहाँ फेरी के यात्रियों ने \n"
          ]
        }
      ],
      "source": [
        "k += 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k + 1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQuGtMCHYO-4",
        "outputId": "23455309-2ebd-4da7-e846-f5f6430768a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Input English sentence: where no sentient creature is harmed\n",
            "Actual Hindi Translation:  जहां कोई संवेदनशील प्राणी को नुकसान नहीं पहुंचाया जाते \n",
            "Predicted Hindi Translation:  जहां कोई संवेदनशील प्राणी को नुकसान नहीं पहुंचाया \n"
          ]
        }
      ],
      "source": [
        "k += 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k + 1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNriQxDwYO-5",
        "outputId": "71224763-3e36-4e70-eb79-e29d332b5a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Input English sentence: doesnt feel like anything\n",
            "Actual Hindi Translation:  कुछ भी महसूस नहीं करता है \n",
            "Predicted Hindi Translation:  कुछ भी महसूस नहीं करते \n"
          ]
        }
      ],
      "source": [
        "k += 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k + 1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLLpQxpRYO-6",
        "outputId": "56be6286-079f-4ef2-e9f2-cd6ea79c1200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Input English sentence: in improving the technology of the heart\n",
            "Actual Hindi Translation:  अपने हृदय की तकनीक के संवर्धन में लगाएं \n",
            "Predicted Hindi Translation:  अपने हृदय की तकनीक के गहरे दिए जाते हैं \n"
          ]
        }
      ],
      "source": [
        "k += 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', x_train[k:k + 1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k + 1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "e8bba4f2be892cbd4f39a9f240acc2c7ebb8cef7264d56c87dbb8c6b0bcbe231"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
